{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **TinyBERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install transformers==4.36.0 torch==2.9.0 scikit-learn==1.7.2 pandas tqdm psutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload merged_fakenewsnet.csv dataset\n",
        "uploaded = files.upload()\n",
        "\n",
        "# df = pd.read_csv(\"merged_fakenewsnet.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning and Validation\n",
        "- Removes rows with missing values in the `clean_title` or `label` columns\n",
        "- Ensures all labels are properly formatted as integers\n",
        "- Displays before/after statistics to verify the cleaning process\n",
        "- Loads the dataset and removes any rows with missing or invalid labels\n",
        "- Converts labels to numeric format and validates data integrity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload the CSV\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Get the notebook's directory and construct absolute path\n",
        "notebook_dir = Path.cwd()\n",
        "if 'notebooks' in str(notebook_dir):\n",
        "    # If running from notebooks folder, go up one level\n",
        "    data_path = notebook_dir.parent / \"data\" / \"merged_fakenewsnet.csv\"\n",
        "    output_path = notebook_dir.parent / \"data\" / \"merged_fakenewsnet_numeric.csv\"\n",
        "else:\n",
        "    # If running from project root\n",
        "    data_path = notebook_dir / \"data\" / \"merged_fakenewsnet.csv\"\n",
        "    output_path = notebook_dir / \"data\" / \"merged_fakenewsnet_numeric.csv\"\n",
        "\n",
        "print(f\"Loading from: {data_path}\")\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(f\"Original shape: {df.shape}\")\n",
        "print(f\"Original labels:\\n{df['label'].value_counts()}\\n\")\n",
        "\n",
        "# Remove any rows where label is not 'fake' or 'real' (e.g., header rows)\n",
        "df = df[df['label'].isin(['fake', 'real'])]\n",
        "\n",
        "# Convert string labels to numeric\n",
        "df['label'] = df['label'].map({'fake': 0, 'real': 1})\n",
        "\n",
        "# Check conversion\n",
        "print(f\"After cleaning and conversion:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Label distribution:\\n{df['label'].value_counts()}\\n\")\n",
        "\n",
        "# Save new version\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Conversion complete! File saved as {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenization & Data Splitting\n",
        "**TinyBERT Tokenizer Initialization**\n",
        "- Loads the pre-trained `huawei-noah/TinyBERT_General_4L_312D` tokenizer from Hugging Face\n",
        "\n",
        "**Dataset Splitting (80/10/10)**\n",
        "- **Training set**: 80% of data for model training\n",
        "- **Validation set**: 10% for hyperparameter tuning and monitoring\n",
        "- **Test set**: 10% for final model evaluation\n",
        "- Uses stratified splitting to maintain class balance across all sets\n",
        "\n",
        "**Tokenization**\n",
        "- Converts text to token IDs with padding and truncation\n",
        "- Sets maximum sequence length to 128 tokens\n",
        "- Returns PyTorch tensors ready for model input\n",
        "\n",
        "**Output**: Three tokenized datasets ready for training, validation, and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initialize TinyBERT Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
        "\n",
        "\n",
        "# Split Dataset (80/10/10)\n",
        "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
        "    df['clean_title'].tolist(),\n",
        "    df['label'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['label']\n",
        ")\n",
        "\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
        "    temp_texts, temp_labels,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=temp_labels\n",
        ")\n",
        "\n",
        "print(\" Dataset split successful!\")\n",
        "print(f\"Train: {len(train_texts)}, Validation: {len(val_texts)}, Test: {len(test_texts)}\\n\")\n",
        "\n",
        "# Tokenization Function\n",
        "def encode_data(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "# Apply Tokenization\n",
        "train_encodings = encode_data(train_texts)\n",
        "val_encodings = encode_data(val_texts)\n",
        "test_encodings = encode_data(test_texts)\n",
        "\n",
        "print(\" Tokenization complete!\")\n",
        "print(f\"Train samples: {len(train_texts)}, Validation: {len(val_texts)}, Test: {len(test_texts)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Custom Dataset and DataLoaders\n",
        "- Defines `FakeNewsDataset` class that wraps tokenized encodings and labels\n",
        "- Implements required methods (`__getitem__`, `__len__`) for PyTorch compatibility\n",
        "- Formats data as dictionaries with input tensors and labels\n",
        "\n",
        "- Creates three dataset instances for training, validation, and testing\n",
        "\n",
        "**DataLoaders**\n",
        "- Wraps datasets in DataLoader objects for automatic batching\n",
        "- **Batch size**: 16 samples per batch\n",
        "- **Training**: Shuffled for better generalization\n",
        "- **Validation/Test**: Not shuffled to maintain consistency\n",
        "\n",
        "**Output**: DataLoaders that efficiently feed batches of data to the model during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define a Custom Dataset Class\n",
        "class FakeNewsDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "# Create Dataset Objects\n",
        "train_dataset = FakeNewsDataset(train_encodings, train_labels)\n",
        "val_dataset = FakeNewsDataset(val_encodings, val_labels)\n",
        "test_dataset = FakeNewsDataset(test_encodings, test_labels)\n",
        "\n",
        "# Create DataLoaders (for batching)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"DataLoaders created successfully!\")\n",
        "print(f\"Train batches: {len(train_loader)}, Validation: {len(val_loader)}, Test: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training with TinyBERT\n",
        "Complete training pipeline for fine-tuning TinyBERT on fake news detection:\n",
        "\n",
        "- Automatically detects and uses GPU if available, otherwise falls back to CPU\n",
        "\n",
        "- Loads pre-trained `huawei-noah/TinyBERT_General_4L_312D` model\n",
        "- Configures for binary classification (2 labels: fake/real)\n",
        "\n",
        "**Optimizer & Learning Rate Scheduler**\n",
        "- **Optimizer**: AdamW with learning rate of 2e-5 (standard for transformer fine-tuning)\n",
        "- **Scheduler**: Linear learning rate decay over training steps\n",
        "- **Epochs**: 3 (typical for fine-tuning pre-trained models)\n",
        "\n",
        "**Training Loop**\n",
        "For each epoch:\n",
        "- **Training Phase**: \n",
        "  - Forward pass through model\n",
        "  - Compute loss\n",
        "  - Backward propagation\n",
        "  - Update weights\n",
        "  - Track average training loss\n",
        "  \n",
        "- **Validation Phase**:\n",
        "  - Evaluate model on validation set without gradient updates\n",
        "  - Monitor validation loss to detect overfitting\n",
        "\n",
        "**Model Saving**\n",
        "- Saves the fine-tuned model to `tinybert_fakenewsnet` directory\n",
        "- Can be reloaded later for inference or further training\n",
        "\n",
        "**Output**: A fine-tuned TinyBERT model specialized for fake news detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, get_scheduler\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# Setup Device (GPU if available)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load TinyBERT Pretrained Model\n",
        "model = BertForSequenceClassification.from_pretrained('huawei-noah/TinyBERT_General_4L_312D', num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer and Scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Training Loop\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\n Epoch {epoch + 1}/{num_epochs}\")\n",
        "    total_loss = 0\n",
        "\n",
        "    # -------- TRAINING PHASE --------\n",
        "    for batch in train_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\" Average training loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # -------- VALIDATION PHASE --------\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\" Validation loss after epoch {epoch + 1}: {avg_val_loss:.4f}\")\n",
        "    model.train()  # switch back to training mode\n",
        "\n",
        "# Save Fine-Tuned Model\n",
        "model.save_pretrained(\"tinybert_fakenewsnet\")\n",
        "print(\"\\n Model saved as 'tinybert_fakenewsnet'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking the trained model\n",
        "!ls tinybert_fakenewsnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Include the Tokenizer\n",
        "tokenizer.save_pretrained(\"tinybert_fakenewsnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for Tokenizer inclusion\n",
        "!ls tinybert_fakenewsnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Downloading the model\n",
        "from google.colab import files\n",
        "!zip -r tinybert_fakenewsnet.zip tinybert_fakenewsnet\n",
        "files.download(\"tinybert_fakenewsnet.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance Evaluation\n",
        "Evaluates the fine-tuned TinyBERT model on the test set:\n",
        "- **Accuracy**: Overall correctness of predictions\n",
        "- **Precision**: Proportion of correct positive predictions\n",
        "- **Recall**: Proportion of actual positives correctly identified\n",
        "- **F1 Score**: Harmonic mean of precision and recall\n",
        "- **AUC-ROC**: Area under the receiver operating characteristic curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Evaluation Mode\n",
        "model.eval()\n",
        "\n",
        "predictions, true_labels, probs = [], [], []\n",
        "\n",
        "# Inference Loop\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        pred_probs = torch.softmax(logits, dim=-1)\n",
        "        preds = torch.argmax(pred_probs, dim=-1)\n",
        "\n",
        "        probs.extend(pred_probs[:, 1].cpu().numpy())\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "# Compute Metrics\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions)\n",
        "recall = recall_score(true_labels, predictions)\n",
        "f1 = f1_score(true_labels, predictions)\n",
        "auc = roc_auc_score(true_labels, probs)\n",
        "\n",
        "# Display Results\n",
        "print(f\"\\nModel Evaluation Results:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "print(f\"AUC:       {auc:.4f}\\n\")\n",
        "\n",
        "print(\"Detailed Classification Report:\\n\")\n",
        "print(classification_report(true_labels, predictions, target_names=['Fake', 'Real']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Operational Efficiency Metrics\n",
        "Evaluates computational efficiency for real-time deployment:\n",
        "- **Inference Latency**: Average time to process samples\n",
        "- **Memory Usage**: GPU/CPU memory consumption during inference\n",
        "- **Model Size**: Total disk space of saved model files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import psutil\n",
        "import numpy as np\n",
        "\n",
        "# -------- INFERENCE LATENCY --------\n",
        "model.eval()\n",
        "latencies = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Measuring Latency\"):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        start_time = time.time()\n",
        "        outputs = model(**batch)\n",
        "        latencies.append((time.time() - start_time) * 1000)  # ms\n",
        "\n",
        "avg_latency = np.mean(latencies)\n",
        "print(f\"\\nInference Latency:\")\n",
        "print(f\"   Average: {avg_latency:.2f} ms/batch ({avg_latency/16:.2f} ms/sample)\")\n",
        "\n",
        "# -------- MEMORY USAGE --------\n",
        "if torch.cuda.is_available():\n",
        "    memory_mb = torch.cuda.memory_allocated(device) / (1024 ** 2)\n",
        "    print(f\"\\nGPU Memory: {memory_mb:.2f} MB\")\n",
        "else:\n",
        "    memory_mb = psutil.Process(os.getpid()).memory_info().rss / (1024 ** 2)\n",
        "    print(f\"\\nCPU Memory: {memory_mb:.2f} MB\")\n",
        "\n",
        "# -------- MODEL SIZE --------\n",
        "model_dir = \"tinybert_fakenewsnet\"\n",
        "total_size = sum(os.path.getsize(os.path.join(dp, f)) \n",
        "                 for dp, dn, fn in os.walk(model_dir) for f in fn)\n",
        "size_mb = total_size / (1024 ** 2)\n",
        "print(f\"\\nModel Size: {size_mb:.2f} MB\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
